"""
ìµœì í™”ëœ ì„ê³„ê°’ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìµœì¢… í‰ê°€
"""

import os
import torch
import numpy as np
import pandas as pd
import json
import logging
from tqdm import tqdm
from transformers import AutoTokenizer
from sklearn.metrics import f1_score, accuracy_score, hamming_loss

from data_loader import UnsmileDataLoader
from dataset import create_dataloaders
from model import create_model

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def load_model_and_predict(model_config: dict, test_df: pd.DataFrame, label_columns: list, device: str):
    """ë‹¨ì¼ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡"""

    model_name = model_config['name']
    model_path = f"./models/{model_name}.pt"

    if not os.path.exists(model_path):
        logger.warning(f"âš ï¸ {model_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    logger.info(f"ğŸ“¦ {model_name} ë¡œë”© ì¤‘...")

    # í† í¬ë‚˜ì´ì €
    tokenizer = AutoTokenizer.from_pretrained(model_config['hf_name'])

    # ë°ì´í„°ë¡œë”
    _, _, test_loader = create_dataloaders(
        train_df=test_df[:1],  # dummy
        val_df=test_df[:1],    # dummy
        test_df=test_df,
        tokenizer=tokenizer,
        label_columns=label_columns,
        batch_size=16,
        max_length=128
    )

    # ëª¨ë¸ ìƒì„±
    model = create_model(
        model_name=model_config['hf_name'],
        num_labels=9,
        use_qlora=model_config.get('use_qlora', False)
    )

    # ê°€ì¤‘ì¹˜ ë¡œë“œ
    model.load_state_dict(torch.load(model_path, map_location=device))
    model = model.to(device)
    model.eval()

    # ì˜ˆì¸¡
    all_probs = []
    all_labels = []

    with torch.no_grad():
        for batch in tqdm(test_loader, desc=f"Predicting {model_name}"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)

            outputs = model(input_ids, attention_mask)
            logits = outputs['logits']
            probs = torch.sigmoid(logits)

            all_probs.append(probs.cpu().numpy())
            all_labels.append(labels.cpu().numpy())

    all_probs = np.concatenate(all_probs, axis=0)
    all_labels = np.concatenate(all_labels, axis=0)

    return all_probs, all_labels


def apply_optimal_thresholds(probs: np.ndarray, thresholds: np.ndarray) -> np.ndarray:
    """ìµœì  ì„ê³„ê°’ ì ìš©í•˜ì—¬ ì˜ˆì¸¡"""
    preds = np.zeros_like(probs, dtype=int)

    for i in range(probs.shape[1]):
        preds[:, i] = (probs[:, i] >= thresholds[i]).astype(int)

    return preds


def evaluate_predictions(labels: np.ndarray, preds: np.ndarray, label_names: list):
    """ì˜ˆì¸¡ ê²°ê³¼ í‰ê°€"""

    logger.info("\n" + "="*80)
    logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ìµœì¢… í‰ê°€ ê²°ê³¼")
    logger.info("="*80)

    # ì „ì²´ ë©”íŠ¸ë¦­
    f1_macro = f1_score(labels, preds, average='macro', zero_division=0)
    f1_micro = f1_score(labels, preds, average='micro', zero_division=0)
    exact_match = accuracy_score(labels, preds)
    hamming_acc = 1 - hamming_loss(labels, preds)

    logger.info(f"\nğŸ† ì „ì²´ ì„±ëŠ¥:")
    logger.info(f"  F1-Macro:        {f1_macro:.4f} ({f1_macro*100:.2f}%)")
    logger.info(f"  F1-Micro:        {f1_micro:.4f} ({f1_micro*100:.2f}%)")
    logger.info(f"  Exact Match:     {exact_match:.4f} ({exact_match*100:.2f}%)")
    logger.info(f"  Hamming Acc:     {hamming_acc:.4f} ({hamming_acc*100:.2f}%) â­")

    # í´ë˜ìŠ¤ë³„ F1
    logger.info(f"\nğŸ“ˆ í´ë˜ìŠ¤ë³„ F1-Score:")
    class_f1_scores = f1_score(labels, preds, average=None, zero_division=0)

    for i, (name, score) in enumerate(zip(label_names, class_f1_scores)):
        bar = "â–ˆ" * int(score * 20)
        logger.info(f"  {name:20s}: {score:.4f} {bar}")

    logger.info("="*80 + "\n")

    # ëª©í‘œ ë‹¬ì„± ì—¬ë¶€
    target = 0.98
    if hamming_acc >= target:
        logger.info(f"ğŸ‰ ëª©í‘œ ë‹¬ì„±! Hamming Accuracy {hamming_acc:.4f} >= {target} âœ…")
    elif hamming_acc >= 0.97:
        logger.info(f"ğŸ‘ ê±°ì˜ ë‹¬ì„±! Hamming Accuracy {hamming_acc:.4f} (ëª©í‘œ: {target})")
        logger.info(f"   ë¶€ì¡±: {(target - hamming_acc)*100:.2f}%p")
    else:
        logger.info(f"âš ï¸ ì¶”ê°€ ê°œì„  í•„ìš”. Hamming Accuracy {hamming_acc:.4f} (ëª©í‘œ: {target})")
        logger.info(f"   ë¶€ì¡±: {(target - hamming_acc)*100:.2f}%p")

    return {
        'f1_macro': float(f1_macro),
        'f1_micro': float(f1_micro),
        'exact_match': float(exact_match),
        'hamming_accuracy': float(hamming_acc),
        'class_f1_scores': {name: float(score) for name, score in zip(label_names, class_f1_scores)}
    }


def main():
    """ë©”ì¸ ìµœì¢… í‰ê°€ íŒŒì´í”„ë¼ì¸"""

    logger.info("\n" + "="*80)
    logger.info("ğŸ¯ ìµœì  ì„ê³„ê°’ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìµœì¢… í‰ê°€")
    logger.info("="*80)

    # ë””ë°”ì´ìŠ¤
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    logger.info(f"\nğŸ’» Device: {device}")

    # 1. ë°ì´í„° ë¡œë“œ
    logger.info("\nğŸ“Š Step 1: ë°ì´í„° ë¡œë”©")
    data_loader = UnsmileDataLoader(data_dir="./data")
    train_df, val_df, test_df = data_loader.load_processed_data()
    label_columns = data_loader.label_columns

    logger.info(f"âœ“ Test ìƒ˜í”Œ ìˆ˜: {len(test_df)}")

    # 2. ìµœì  ì„ê³„ê°’ ë¡œë“œ
    logger.info("\nğŸ“Š Step 2: ìµœì  ì„ê³„ê°’ ë¡œë”©")

    threshold_path = "./results/optimal_thresholds.json"
    if not os.path.exists(threshold_path):
        logger.error(f"âŒ {threshold_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        logger.error("ë¨¼ì € optimize_thresholds.pyë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    with open(threshold_path, 'r', encoding='utf-8') as f:
        threshold_data = json.load(f)

    optimal_thresholds = np.array(threshold_data['optimal_thresholds'])

    logger.info(f"âœ“ ìµœì  ì„ê³„ê°’ ë¡œë“œ ì™„ë£Œ")
    for name, thresh in zip(label_columns, optimal_thresholds):
        logger.info(f"  {name:20s}: {thresh:.4f}")

    # 3. ëª¨ë¸ ì„¤ì • (3ê°œ ëª¨ë¸)
    models_config = [
        {
            'name': 'kcelectra',
            'hf_name': 'beomi/KcELECTRA-base',
            'use_qlora': False
        },
        {
            'name': 'soongsil',
            'hf_name': 'snunlp/KR-SBERT-V40K-klueNLI-augSTS',
            'use_qlora': False
        },
        {
            'name': 'roberta_base',
            'hf_name': 'klue/roberta-base',
            'use_qlora': False
        }
    ]

    # 4. ê° ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡
    logger.info("\nğŸ“Š Step 3: ê° ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡")
    all_model_probs = []
    labels = None

    for config in models_config:
        result = load_model_and_predict(config, test_df, label_columns, device)

        if result is not None:
            probs, lbls = result
            all_model_probs.append(probs)
            if labels is None:
                labels = lbls

    if len(all_model_probs) == 0:
        raise ValueError("ì˜ˆì¸¡ ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤!")

    # 5. ì•™ìƒë¸” (ë‹¨ìˆœ í‰ê· )
    logger.info("\nğŸ“Š Step 4: ì•™ìƒë¸” (ë‹¨ìˆœ í‰ê· )")

    # ë‹¨ìˆœ í‰ê·  (ê°€ì¤‘ì¹˜ ì—†ìŒ)
    ensemble_probs = np.mean(all_model_probs, axis=0)
    logger.info(f"âœ“ ì•™ìƒë¸” ì™„ë£Œ: {len(all_model_probs)}ê°œ ëª¨ë¸ (ë‹¨ìˆœ í‰ê· )")

    # 6. ìµœì  ì„ê³„ê°’ ì ìš©
    logger.info("\nğŸ“Š Step 5: ìµœì  ì„ê³„ê°’ ì ìš©")
    ensemble_preds = apply_optimal_thresholds(ensemble_probs, optimal_thresholds)

    logger.info(f"âœ“ ì˜ˆì¸¡ ì™„ë£Œ: {ensemble_preds.shape}")
    logger.info(f"âœ“ ê¸ì • ì˜ˆì¸¡ ë¹„ìœ¨: {ensemble_preds.mean()*100:.2f}%")

    # 7. ìµœì¢… í‰ê°€
    logger.info("\nğŸ“Š Step 6: ìµœì¢… í‰ê°€")
    final_metrics = evaluate_predictions(labels, ensemble_preds, label_columns)

    # 8. ê²°ê³¼ ì €ì¥
    logger.info("\nğŸ“Š Step 7: ê²°ê³¼ ì €ì¥")

    final_metrics['optimal_thresholds'] = optimal_thresholds.tolist()
    final_metrics['models'] = [m['name'] for m in models_config]
    final_metrics['ensemble_method'] = 'simple_average'

    output_path = "./results/final_test_results.json"
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(final_metrics, f, indent=2, ensure_ascii=False)

    logger.info(f"âœ… ìµœì¢… ê²°ê³¼ ì €ì¥: {output_path}")

    # 9. ì˜ˆì¸¡ ê²°ê³¼ CSV ì €ì¥
    results_df = test_df[['text']].copy()

    # ì˜ˆì¸¡ ë ˆì´ë¸” ì¶”ê°€
    for i, col in enumerate(label_columns):
        results_df[f'pred_{col}'] = ensemble_preds[:, i]
        results_df[f'prob_{col}'] = ensemble_probs[:, i]

    # ì‹¤ì œ ë ˆì´ë¸” ì¶”ê°€
    for i, col in enumerate(label_columns):
        results_df[f'true_{col}'] = test_df[col].values

    csv_path = "./results/final_test_predictions.csv"
    results_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
    logger.info(f"âœ… ì˜ˆì¸¡ ê²°ê³¼ CSV ì €ì¥: {csv_path}")

    logger.info("\n" + "="*80)
    logger.info("âœ… ìµœì¢… í‰ê°€ ì™„ë£Œ!")
    logger.info("="*80)


if __name__ == "__main__":
    main()
