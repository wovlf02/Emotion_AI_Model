# 02. 데이터 분석

## 📊 UnSmile 데이터셋 분석

---

## 1. 데이터셋 개요

### 1.1 데이터 출처

| 항목 | 내용 |
|------|------|
| **제공** | Smilegate AI |
| **목적** | 한국어 혐오 표현 탐지 연구 |
| **수집 원천** | 뉴스 댓글, 온라인 커뮤니티 |
| **레이블링** | 전문가 어노테이션 |

### 1.2 데이터 구성

| 파일 | 샘플 수 | 용도 |
|------|---------|------|
| `unsmile_train.tsv` | ~15,000 | 학습 |
| `unsmile_dev.tsv` | ~1,500 | 검증 (임계값 최적화) |
| `unsmile_test.tsv` | ~1,500 | 최종 평가 |
| **총계** | **~18,000** | |

### 1.3 레이블 구조

**다중 라벨 분류 (Multi-Label Classification)**

하나의 텍스트에 여러 레이블이 동시에 적용될 수 있습니다.

```
텍스트: "김치녀는 한남이랑 꼭 닮았네"

레이블:
├── 여성/가족: 1 ✓
├── 남성: 1 ✓
├── 성소수자: 0
├── 인종/국적: 0
├── 연령: 0
├── 지역: 0
├── 종교: 0
├── 기타 혐오: 0
└── 악플/욕설: 1 ✓
```

---

## 2. 클래스 분포 분석

### 2.1 레이블별 분포

```
┌─────────────────────────────────────────────────────────────┐
│                    레이블별 데이터 분포                      │
├─────────────────────────────────────────────────────────────┤
│  Clean (청정)    ████████████████████████░  24.9%  (다수)   │
│  악플/욕설       ████████████████████░░░░░  20.9%  (다수)   │
│  인종/국적       ███████████░░░░░░░░░░░░░░  11.5%  (중간)   │
│  여성/가족       ██████████░░░░░░░░░░░░░░░  10.6%  (중간)   │
│  남성            ████████░░░░░░░░░░░░░░░░░   8.9%  (중간)   │
│  종교            ███████░░░░░░░░░░░░░░░░░░   7.8%  (중간)   │
│  성소수자        ███████░░░░░░░░░░░░░░░░░░   7.5%  (중간)   │
│  지역            ██████░░░░░░░░░░░░░░░░░░░   7.0%  (소수)   │
│  연령            ███░░░░░░░░░░░░░░░░░░░░░░   4.0%  (극소수) │
│  기타 혐오       ███░░░░░░░░░░░░░░░░░░░░░░   3.7%  (극소수) │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 불균형 비율

| 레이블 | 샘플 수 | 비율 | 불균형 심각도 |
|--------|---------|------|---------------|
| Clean | 3,739 | 24.9% | 다수 클래스 |
| 악플/욕설 | 3,146 | 20.9% | 다수 클래스 |
| 인종/국적 | 1,728 | 11.5% | 중간 |
| 여성/가족 | 1,599 | 10.6% | 중간 |
| 남성 | 1,347 | 8.9% | 중간 |
| 종교 | 1,181 | 7.8% | 중간 |
| 성소수자 | 1,138 | 7.5% | 중간 |
| 지역 | 1,052 | 7.0% | 소수 클래스 |
| 연령 | 603 | 4.0% | 극소수 클래스 |
| 기타 혐오 | 569 | 3.7% | 극소수 클래스 |

**불균형 비율**: 다수 클래스(Clean) vs 극소수 클래스(기타 혐오) = **약 6.5:1**

---

## 3. 클래스 불균형 문제

### 3.1 문제점

1. **학습 편향**: 모델이 다수 클래스로 편향 학습
2. **소수 클래스 무시**: 연령, 기타 혐오 클래스 탐지 실패
3. **정확도 착시**: 다수 클래스만 맞춰도 높은 정확도

### 3.2 해결 전략

| 전략 | 설명 | 적용 |
|------|------|------|
| **AEDA 데이터 증강** | 소수 클래스 오버샘플링 | ✅ |
| **가중 손실 함수** | 소수 클래스에 높은 가중치 | ✅ |
| **임계값 최적화** | 클래스별 최적 임계값 탐색 | ✅ |

---

## 4. 텍스트 특성 분석

### 4.1 텍스트 길이 분포

```
┌─────────────────────────────────────────────────────────────┐
│                    텍스트 길이 분포                          │
├─────────────────────────────────────────────────────────────┤
│  0-20자     ████████████████████  35%                       │
│  21-50자    ██████████████████████████████  45%             │
│  51-100자   ████████████  15%                               │
│  100자 이상  ████  5%                                        │
└─────────────────────────────────────────────────────────────┘

평균 길이: 약 35자
최대 길이: 약 500자
95 백분위: 약 100자
```

**결정**: `max_length = 128` (95% 이상 커버)

### 4.2 한국어 인터넷 언어 특성

**1) 신조어 및 은어**

| 유형 | 예시 | 대상 |
|------|------|------|
| 남성 비하 | 한남, 한남충, 자지충 | 남성 |
| 여성 비하 | 김치녀, 맘충, 보슬 | 여성/가족 |
| 연령 비하 | 틀딱, 급식충, 젊친 | 연령 |
| 지역 비하 | 홍어, 쥐라도 | 지역 |
| 종교 비하 | 개독, 빠구리 | 종교 |

**2) 난독화 표현**

| 원본 | 난독화 | 방식 |
|------|--------|------|
| 씨발 | 10발, ㅅㅂ, 시x | 숫자/초성/특수문자 |
| 개새끼 | 개ㅅㄲ, 개ㅅ끼 | 초성 변환 |

**3) 맥락 의존적 표현**

```
❌ 혐오 아님: "아 나 급식충이다!" (자조적 표현)
✅ 혐오 표현: "급식충들이 뭘 알아" (타인 비하)
```

---

## 5. 레이블 간 상관관계

### 5.1 동시 출현 패턴

| 조합 | 동시 출현율 | 해석 |
|------|-------------|------|
| 여성/가족 + 악플/욕설 | 45% | 여성 혐오 시 욕설 동반 |
| 남성 + 악플/욕설 | 42% | 남성 혐오 시 욕설 동반 |
| 인종/국적 + 악플/욕설 | 38% | 인종 혐오 시 욕설 동반 |

### 5.2 평균 레이블 수

- **평균**: 1.3개 레이블/샘플
- **최대**: 4개 이상 레이블 동시 존재

---

## 6. 전처리 전략

### 6.1 텍스트 정제

```python
# 최소한의 정제만 수행 (원본 보존 우선)
def clean_text(text):
    # 1. 불필요한 공백 제거
    text = re.sub(r'\s+', ' ', text).strip()
    
    # 2. 반복 문자 축약 (ㅋㅋㅋㅋ → ㅋㅋ)
    text = re.sub(r'(.)\1{3,}', r'\1\1', text)
    
    return text
```

**주의**: 특수문자 무조건 제거 ❌ (난독화 표현 손실 방지)

### 6.2 토크나이징

| 모델 | 토크나이저 | 특징 |
|------|-----------|------|
| KcELECTRA | BPE | 한국어 인터넷 언어 특화 |
| SoongsilBERT | WordPiece | 일반 한국어 |
| RoBERTa | BPE | KLUE 코퍼스 학습 |

### 6.3 데이터 분할

```
원본 데이터
├── Train (unsmile_train.tsv) → 학습용
├── Dev (unsmile_dev.tsv) → 검증용 (임계값 최적화)
└── Test (unsmile_test.tsv) → 최종 평가 (1회만 사용)
```

---

## 7. AEDA 데이터 증강

### 7.1 AEDA란?

**AEDA (Adaptive Easier Data Augmentation)**

텍스트에 구두점을 무작위로 삽입하여 데이터를 증강하는 기법입니다.

```
원본: "한남충들 진짜 싫다"
증강: "한남충들. 진짜, 싫다!"
```

### 7.2 왜 AEDA인가?

| 기법 | 한계 | AEDA 장점 |
|------|------|-----------|
| 유의어 교체 | 혐오 단어 유의어 없음 | 단어 변경 없음 |
| 역번역 | 혐오 의미 소실 | 의미 보존 |
| 무작위 삭제 | 핵심 단어 삭제 위험 | 삭제 없음 |

### 7.3 적용 방식

```python
class AEDAAugmenter:
    def __init__(self, punc_ratio=0.3):
        self.punctuations = ['.', ',', '!', '?', ';', ':']
    
    def augment(self, text):
        words = text.split()
        for i, word in enumerate(words):
            if random.random() < 0.3:
                words[i] = word + random.choice(self.punctuations)
        return ' '.join(words)
```

### 7.4 증강 대상

| 클래스 | 증강 배율 | 이유 |
|--------|-----------|------|
| 연령 | 3배 | 극소수 클래스 (4.0%) |
| 기타 혐오 | 3배 | 극소수 클래스 (3.7%) |
| 지역 | 2배 | 소수 클래스 (7.0%) |

---

## 8. 핵심 인사이트

### 8.1 데이터 분석에서 얻은 교훈

1. **불균형 심각**: 최대 6.5배 불균형 → 가중 손실, 증강 필수
2. **다중 라벨**: 평균 1.3개 레이블 → Sigmoid + BCE 필수
3. **한국어 특수성**: 신조어/난독화 → 전처리 최소화

### 8.2 모델 설계에 반영

| 분석 결과 | 설계 결정 |
|----------|-----------|
| 클래스 불균형 | AEDA 증강 + 가중 손실 |
| 다중 라벨 | Sigmoid 활성화 + BCEWithLogitsLoss |
| 짧은 텍스트 | max_length = 128 |
| 맥락 의존성 | 대형 PLM 앙상블 |

---

**이전 문서**: [01_프로젝트_개요.md](01_프로젝트_개요.md)  
**다음 문서**: [03_모델_아키텍처.md](03_모델_아키텍처.md)

