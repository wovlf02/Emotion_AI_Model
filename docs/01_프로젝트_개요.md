# 01. 프로젝트 개요

## 📋 프로젝트 정보

| 항목 | 내용 |
|------|------|
| **프로젝트명** | UnSmile 한국어 혐오 표현 탐지 AI |
| **목표** | 9개 혐오 카테고리 동시 탐지 (다중 라벨 분류) |
| **데이터셋** | UnSmile (Smilegate AI) |
| **최종 성능** | Hamming Accuracy 96.72%, F1-Macro 82.91% |

---

## 1. 프로젝트 배경

### 1.1 사회적 필요성

온라인 커뮤니티와 소셜 미디어에서 혐오 표현이 급증하고 있습니다.

**현황:**
- 2021년 기준 사이버 폭력 신고 건수 **전년 대비 40% 증가**
- 익명성에 기반한 무분별한 혐오 표현 확산
- 특정 집단(여성, 남성, 성소수자, 특정 지역 등)에 대한 차별적 언어 사용 증가

**기존 해결책의 한계:**

| 방식 | 한계점 |
|------|--------|
| 단순 욕설 필터링 | "ㅅㅂ", "시x" 등 변형 표현 탐지 불가 |
| 이진 분류 (악성/정상) | 혐오 유형을 구분하지 못함 |
| 키워드 기반 탐지 | 문맥을 이해하지 못해 오탐 발생 |

### 1.2 기술적 도전 과제

**1) 다중 라벨 분류 (Multi-Label Classification)**
- 하나의 문장이 **여러 혐오 유형을 동시에 포함** 가능
- 예: "김치녀는 한남이랑 꼭 닮았네" → 여성 혐오 + 남성 혐오

**2) 극심한 클래스 불균형**
- Clean: 24.9% vs 연령: 4.0% vs 기타 혐오: 3.7%

**3) 한국어 인터넷 언어의 특수성**
- 신조어: "한남", "틀딱", "급식충"
- 난독화: "10발", "개^독"
- 맥락 의존적 표현: 욕설 없이도 혐오가 될 수 있음

---

## 2. 프로젝트 목표

### 2.1 정량적 목표

| 지표 | 목표 | 달성 |
|------|------|------|
| Hamming Accuracy | 95% 이상 | **96.72%** ✅ |
| F1-Macro | 80% 이상 | **82.91%** ✅ |

### 2.2 정성적 목표

1. **혐오 유형 세분화**: 9개 카테고리 동시 탐지
2. **실서비스 적용 가능**: 높은 정확도와 안정성
3. **재현 가능한 학습 파이프라인**: 문서화된 코드와 전략

---

## 3. 혐오 표현 카테고리

UnSmile 데이터셋은 **9개의 혐오 카테고리**를 정의합니다.

| 카테고리 | 설명 | 예시 |
|----------|------|------|
| **여성/가족** | 여성 및 가족 관련 혐오 | "김치녀", "맘충" |
| **남성** | 남성 관련 혐오 | "한남충" |
| **성소수자** | LGBTQ+ 관련 혐오 | - |
| **인종/국적** | 인종 및 국적 관련 혐오 | "조선족", "짱깨" |
| **연령** | 연령 관련 혐오 | "틀딱", "급식충" |
| **지역** | 특정 지역 관련 혐오 | "홍어" |
| **종교** | 종교 관련 혐오 | "개독" |
| **기타 혐오** | 기타 유형의 혐오 | - |
| **악플/욕설** | 일반적인 악성 댓글 | 욕설, 비하 표현 |

---

## 4. 해결 전략 요약

### 4.1 핵심 전략

1. **데이터 증강 (AEDA)**: 소수 클래스 오버샘플링
2. **3-모델 하이브리드 앙상블**: KcELECTRA, SoongsilBERT, RoBERTa-Base
3. **클래스별 임계값 최적화**: F1-Score 최대화 임계값 탐색
4. **가중 소프트 보팅**: 모델 예측 확률의 가중 평균

### 4.2 기술 스택

| 분류 | 기술 |
|------|------|
| **언어** | Python 3.8+ |
| **딥러닝** | PyTorch 2.0+, Transformers 4.30+ |
| **모델** | KcELECTRA, SoongsilBERT, KLUE-RoBERTa |
| **최적화** | AdamW, Cosine Scheduler, Mixed Precision |
| **평가** | Scikit-learn |

---

## 5. 프로젝트 구조

```
Emotion_Project/
├── run_train.py                 # 학습 실행 스크립트
├── run_inference.py             # 추론 실행 스크립트
├── run_final_inference.py       # 최종 평가 실행 스크립트
├── run_optimize_thresholds.py   # 임계값 최적화 실행 스크립트
│
├── src/                         # 소스 코드
│   ├── train.py                 # 메인 학습 로직
│   ├── inference.py             # 추론 로직
│   ├── final_inference.py       # 최종 평가 로직
│   ├── optimize_thresholds.py   # 임계값 최적화 로직
│   ├── data_loader.py           # 데이터 로딩
│   ├── dataset.py               # PyTorch Dataset
│   ├── model.py                 # 모델 아키텍처
│   └── aeda_augmentation.py     # 데이터 증강
│
├── data/                        # 데이터
├── models/                      # 학습된 모델
├── results/                     # 실험 결과
└── docs/                        # 문서
```

---

## 6. 참고 자료

### 데이터셋 및 모델

- **UnSmile 데이터셋**: [Smilegate AI GitHub](https://github.com/smilegate-ai/korean_unsmile_dataset)
- **학습된 모델 다운로드**: [Google Drive](https://drive.google.com/drive/folders/1Noow6HkhI6hkAuggptroiNmbUVGDbu1u?usp=sharing)
  - `kcelectra.pt`: KcELECTRA 학습 모델
  - `soongsil.pt`: SoongsilBERT 학습 모델
  - `roberta_base.pt`: RoBERTa-Base 학습 모델

### 사전 학습 모델

- **KcELECTRA**: [Hugging Face](https://huggingface.co/beomi/KcELECTRA-base)
- **SoongsilBERT**: [Hugging Face](https://huggingface.co/soongsil-ai/soongsil-bert-base)
- **KLUE-RoBERTa**: [Hugging Face](https://huggingface.co/klue/roberta-base)

---

**다음 문서**: [02_데이터_분석.md](02_데이터_분석.md)

